---
title: "Anomaly_Detection"
author: "Group B"
date: "20/02/2021"
output: pdf_document
urlcolor: blue
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(warning =FALSE,echo = TRUE)
```

## Abstract
 


Anomaly detection or Outlier detection identifies data points, events or observations that deviate from dataset's normal behavior. Anomalous data indicate critical incidents or potential opportunities. In order to take advantage of opportunities or fix costly problems anomaly detection has to be done in real time. Unsupervised machine learning models can be used to automate anomaly detection. Unsupervised anomaly detection algorithms scores data based on intrinsic properties of the dataset. Distances and densities are used to give an estimation what is normal and what is an outlier. Anomaly detection monitor is a tool developed for an online retailer to check product quality issues like profit opportunities and sales glitches. The application is built using R and Shinyapp following CRISP-DM framework. 



## Business Case





## Objectives

Detect point anomalies from superstore dataset using K-NN and clustering methods



### Import data

```{r message=FALSE}
#load libraries
library(readxl)
library(tidyr)
library(dplyr)
library(ggplot2)
library(anomalize)
library(lemon)
library(DMwR)
#library(CORElearn)
library(outForest)



```
 

```{r}
#read data from file
superstore<-read_excel("superstore.xls")
```
```{r  include=FALSE}
#intial structure
dim(superstore) # 9994* 20
str(superstore)
```



## Data Understanding

US Superstore dataset is sourced from [US superstore dataset](https://www.kaggle.com/juhi1994/superstore) . The dataset have online orders for  Superstores in U.S. from 2014-2018. Tableau community is the owner of the dataset. The dataset has 9994 records and 21 attributes.




```{r include=FALSE}

#print dataset details
data_superstore<-as.data.frame( summary.default(superstore))
data_superstore<-data_superstore[-c(1:42),c(1,3)]
names(data_superstore)<-c("Attribute"," Data Type")
rownames(data_superstore)<-c()
data_superstore$Description<-c("row number","unique order number","order placed date","order shipping date","shipping mode of  order","unique customer id for order","name of customer","section of product","country based on order","city based on order","state based on order","pin code","region based on order","product id of  product","category of product","sub-category of product","name of product","selling price of product","order quantity","discount on product","profit from product")
knit_print.data.frame <- lemon_print

```

```{r caption ="Dataset description" ,render=lemon_print}
data_superstore
```

## Data Preparation


```{r}
#name columns
names(superstore)<-c("rowid","orderid","order_date","ship_date","ship_mode","customer_id",
                     "customer_name","segment","country","city","state","postal_code",
                     "region","product_id","category","sub_category","product_name",
                     "sales_amt","quantity","discount","profit_amt")

#drop columns with redundant information
superstore[,c("rowid","customer_name","country")]<-NULL


#convert to date 
superstore$order_date<-as.Date(superstore$order_date,format="%Y-%m-%d")
superstore$ship_date<-as.Date(superstore$ship_date,format="%Y-%m-%d")
```



## Descriptive Analysis




### Continous variables summary

```{r}
superstore %>% 
    select_if(is.numeric)%>% 
    summary()
  
```
### Profit 
```{r}
ggplot(data=superstore)+
  geom_histogram(mapping=aes(x=profit_amt),fill="green3")+
  coord_cartesian(ylim = c(0, 100))+
  labs(title=" Profit Distribution")



```

### Sales

```{r}
ggplot(data=superstore)+
  geom_histogram(mapping=aes(x=sales_amt),fill="sienna3")+
  coord_cartesian(ylim = c(0, 100))+labs(title=" Sales Distribution")

```

### Discount


```{r}

ggplot(data=superstore)+
  geom_histogram(mapping=aes(x=discount),fill="cyan3")+
  labs(title=" Discount Distribution")
```

### Sales Profit 


```{r}

ggplot(data = superstore) +
  geom_point(mapping = aes(x = sales_amt, y = profit_amt),colour="limegreen")+
  labs(title=" Sales Profit Distribution")
  

```


### Profit Discount


```{r}

ggplot(data = superstore) +
  geom_point(mapping = aes(x = profit_amt, y = discount),colour="violetred3")+
  labs(title=" Profit Discount Distribution")

```

### Sales by Year

```{r}
ggplot(data=superstore,aes(x = order_date, y =sales_amt)) +
      geom_point(color = "darkorchid3") +
      labs(title=" Sales by Year")
```

### Total Sales by Year

```{r}


sales_year<-aggregate(superstore$sales_amt,by=list(year=format(superstore$order_date, "%Y")),FUN=sum)
names(sales_year)<-c("order_year","sales_total")



ggplot(data=sales_year,aes(x = order_year, y =sales_total)) +
      geom_bar(stat="identity",fill = "orange3") +
      labs(title=" Total Sales by Year")



```


### Profit by Year

```{r}

profit_year<-aggregate(superstore$profit_amt,by=list(year=format(superstore$order_date, "%Y")),FUN=sum)
names(profit_year)<-c("order_year","profit_total")


ggplot(data=profit_year,aes(x = order_year, y =profit_total)) +
      geom_bar(stat="identity",fill = "pink3") +
      labs(title=" Total Profit by Year")



```



```{r}
# total product id 
count_product_id<-unique(superstore$product_id)
length(count_product_id)


```
```{r}
#total product name
count_product_name<-unique(superstore$product_name)
length(count_product_name)



```


```{r}
#product name and product id mismatch
superstore %>% 
  distinct(product_name,product_id) %>% 
  group_by(product_id) %>% 
  filter(n()>1) %>% 
  select(product_id)


```


```{r}
#total category and subcategory 

count_category<-unique(superstore$category)
length(count_category)


count_subcategory<-unique(superstore$sub_category)
length(count_subcategory)


superstore %>% 
  distinct(category,sub_category)


```
```{r}

superstore_sales<-superstore %>% 
                  select(order_date,sales_amt)


superstore_sales<-as_tibble(superstore_sales)


```

```{r}

# superstore_sales_anomalized <- superstore_sales %>%
#     time_decompose(sales_amt, merge = TRUE) %>%
#     anomalize(remainder) %>%
#     time_recompose()



```


## Model

### Local Outlier Factor Algorithm  -Nearest neighbour method 

LOF uses density based methods to calculate degree of outlying.LOF is a unsupervised anomaly detection technique, evry point in the datase is assigned LOF score based on the threshold value it classify the datapoints as outlier or non-outlier.

```{r}



#remove duplicates rows 
superstore_unq<-superstore[!duplicated(superstore[c("sales_amt","profit_amt","quantity","discount")]),]

#select numerical variables
superstore_lof<-superstore_unq[,c("sales_amt","profit_amt","quantity","discount")]



 # for k=10
 lof_scores <- lofactor(superstore_lof, k=10)
 plot(density(lof_scores))
```

### Manual Evaluation

```{r}

 #top 5 outliers transactons
 lof_outliers <- order(lof_scores >2, decreasing=T)[1:13]
 superstore_unq[lof_outliers,]

 
```


```{r}

#new column for outlier status

outlier_orderid<-superstore_unq[which(lof_scores >2),1]
vec<-as.vector(outlier_orderid$orderid)

 
superstore_unq<-mutate(superstore_unq,outlier_status=ifelse(orderid %in% (vec) ,"Yes","No"))

x<-subset(superstore_unq,superstore_unq$outlier_status=="Yes")
x

```




## Plot LOF outliers

```{r}


pch <- rep(".", 7000)
pch[lof_outliers] <- "+"
col <- rep("black",7000)
col[lof_outliers] <- "red"
pairs(superstore_lof, pch=pch, col=col)

```



## Random Forest Algorithm 

outForest is a random forest based implementation of the method. Each numeric variable is regressed onto all other variables using a random forest. If the scaled absolute difference between observed value and out-of-bag prediction is suspiciouly large (e.g. more than three times the RMSE of the out-of-bag predictions), then a value is considered an outlier. After identification of outliers, they can be replaced e.g. by predictive mean matching from the non-outliers.

```{r}
#dataframe for outforest
superstore_out<-superstore_unq[,c("sales_amt","profit_amt","quantity","discount")]

#fit outforest
outforest_outlier<-outForest(superstore_out)

```
### Manual Evaluation 

Observed same set of top outliers as LOF algorithm

```{r}

#outlier rows, observed values, predicted and RMSE
head(outliers(outforest_outlier),13)

```


```{r}

# Outliers per variable
plot(outforest_outlier)


```






## Responsible ML Framework




## Conclusion




## Bibliography





