---
title: "Anomaly_Detection"
author: "Group B"
date: "20/02/2021"
output: pdf_document
urlcolor: blue
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(warning =FALSE,echo = TRUE)
```

## Abstract
 


Anomaly detection or Outlier detection identifies data points, events or observations that deviate from dataset's normal behavior. Anomalous data indicate critical incidents or potential opportunities. In order to take advantage of opportunities or fix costly problems anomaly detection has to be done in real time. Unsupervised machine learning models can be used to automate anomaly detection. Unsupervised anomaly detection algorithms scores data based on intrinsic properties of the dataset. Distances and densities are used to give an estimation what is normal and what is an outlier. Anomaly detection monitor is a tool developed for an online retailer to check product quality issues like profit opportunities and sales glitches. The application is built using R and Shinyapp following CRISP-DM framework. 



## Business Case





## Objectives

Detect point anomalies from superstore dataset using K-NN and clustering methods



### Import data

```{r message=FALSE}
#load libraries
library(readxl)
library(tidyr)
library(dplyr)
library(ggplot2)
library(anomalize)
library(lemon)
library(DMwR)
#library(CORElearn)
library(outForest)
library(factoextra)
library(cluster)
library(lubridate)
#library(reshape2)
#library(dbscan)
library(fpc)



```
 

```{r}
#read data from file
superstore<-read_excel("superstore.xls")
```
```{r  include=FALSE}
#intial structure
dim(superstore) # 9994* 20
str(superstore)
```



## Data Understanding

US Superstore dataset is sourced from [US superstore dataset](https://www.kaggle.com/juhi1994/superstore) . The dataset have online orders for  Superstores in U.S. from 2014-2018. Tableau community is the owner of the dataset. The dataset has 9994 records and 21 attributes.




```{r include=FALSE}

#print dataset details
data_superstore<-as.data.frame( summary.default(superstore))
data_superstore<-data_superstore[-c(1:42),c(1,3)]
names(data_superstore)<-c("Attribute"," Data Type")
rownames(data_superstore)<-c()
data_superstore$Description<-c("row number","unique order number","order placed date","order shipping date","shipping mode of  order","unique customer id for order","name of customer","section of product","country based on order","city based on order","state based on order","pin code","region based on order","product id of  product","category of product","sub-category of product","name of product","selling price of product","order quantity","discount on product","profit from product")
knit_print.data.frame <- lemon_print

```

```{r caption ="Dataset description" ,render=lemon_print}
data_superstore
```

## Data Preparation


```{r}
#name columns
names(superstore)<-c("rowid","orderid","order_date","ship_date","ship_mode","customer_id",
                     "customer_name","segment","country","city","state","postal_code",
                     "region","product_id","category","sub_category","product_name",
                     "sales_amt","quantity","discount","profit_amt")

#drop columns with redundant information
superstore[,c("rowid","customer_name","country")]<-NULL


#convert to date 
superstore$order_date<-as.Date(superstore$order_date,format="%Y-%m-%d")
superstore$ship_date<-as.Date(superstore$ship_date,format="%Y-%m-%d")

# add day columns
superstore$orderday<-yday(superstore$order_date)
superstore$shipday<-yday(superstore$ship_date)




```



## Descriptive Analysis




### Continous variables summary

```{r}
superstore %>% 
    select_if(is.numeric)%>% 
    summary()
  
```
### Profit 
```{r}
ggplot(data=superstore)+
  geom_histogram(mapping=aes(x=profit_amt),fill="green3")+
  coord_cartesian(ylim = c(0, 100))+
  labs(title=" Profit Distribution")



```

### Sales

```{r}
ggplot(data=superstore)+
  geom_histogram(mapping=aes(x=sales_amt),fill="sienna3")+
  coord_cartesian(ylim = c(0, 100))+labs(title=" Sales Distribution")

```

### Discount


```{r}

ggplot(data=superstore)+
  geom_histogram(mapping=aes(x=discount),fill="cyan3")+
  labs(title=" Discount Distribution")
```

### Sales Profit 


```{r}

ggplot(data = superstore) +
  geom_point(mapping = aes(x = sales_amt, y = profit_amt),colour="limegreen")+
  labs(title=" Sales Profit Distribution")
  

```
From the Sales Profit distribution we can visually detect the outliers and let see if our algorithm can detect.

### Profit Discount


```{r}

ggplot(data = superstore) +
  geom_point(mapping = aes(x = profit_amt, y = discount),colour="violetred3")+
  labs(title=" Profit Discount Distribution")

```

### Sales by Year

```{r}
ggplot(data=superstore,aes(x = order_date, y =sales_amt)) +
      geom_point(color = "darkorchid3") +
      labs(title=" Sales by Year")
```

### Total Sales by Year

```{r}


sales_year<-aggregate(superstore$sales_amt,by=list(year=format(superstore$order_date, "%Y")),FUN=sum)
names(sales_year)<-c("order_year","sales_total")



ggplot(data=sales_year,aes(x = order_year, y =sales_total)) +
      geom_bar(stat="identity",fill = "orange3") +
      labs(title=" Total Sales by Year")



```


### Profit by Year

```{r}

profit_year<-aggregate(superstore$profit_amt,by=list(year=format(superstore$order_date, "%Y")),FUN=sum)
names(profit_year)<-c("order_year","profit_total")


ggplot(data=profit_year,aes(x = order_year, y =profit_total)) +
      geom_bar(stat="identity",fill = "pink3") +
      labs(title=" Total Profit by Year")



```



```{r}
# total product id 
count_product_id<-unique(superstore$product_id)
length(count_product_id)


```
```{r}
#total product name
count_product_name<-unique(superstore$product_name)
length(count_product_name)



```


```{r}
#product name and product id mismatch
superstore %>% 
  distinct(product_name,product_id) %>% 
  group_by(product_id) %>% 
  filter(n()>1) %>% 
  select(product_id)


```


```{r}
#total category and subcategory 

count_category<-unique(superstore$category)
length(count_category)


count_subcategory<-unique(superstore$sub_category)
length(count_subcategory)


superstore %>% 
  distinct(category,sub_category)


```
```{r}

superstore_sales<-superstore %>% 
                  select(order_date,sales_amt)


superstore_sales<-as_tibble(superstore_sales)


```

```{r}

# superstore_sales_anomalized <- superstore_sales %>%
#     time_decompose(sales_amt, merge = TRUE) %>%
#     anomalize(remainder) %>%
#     time_recompose()



```



## Model

### Local Outlier Factor Algorithm  -Nearest neighbour method 

LOF uses density based methods to calculate degree of outlying.LOF is a unsupervised anomaly detection technique, every point in the dataset is assigned LOF score based on the threshold value it classify the datapoints as outlier or non-outlier.
It follows a non parametric method.It uses Euclidian distance and kNN to estimate local density.




```{r}

#remove duplicates rows 
superstore_unq<-superstore[!duplicated(superstore[c("sales_amt","profit_amt","quantity","discount","orderday","shipday")]),]

#select numerical variables
superstore_lof<-superstore_unq[,c("sales_amt","profit_amt","quantity","discount","orderday","shipday")]


```


```{r}

 # for k=10 ,lof produces a vector of local outlier factor for each data point
 lof_scores <- lofactor(superstore_lof, k=10)
 plot(density(lof_scores))
```

### Manual Evaluation

```{r}

 #top 5 outliers transactons , greater the lof_scores farther ppoitn is faar from the cluster.Choosing values for score greater than 2
 lof_outliers <- order(lof_scores>2, decreasing=T)[1:22]
 superstore_unq[lof_outliers,]

 
```


```{r}



#outliers for z-score >2(how far an observation is from the mean)

outlier_orderid<-superstore_unq[which(lof_scores >2),1]
vec<-as.vector(outlier_orderid$orderid)


#new column for outlier status
 
superstore_unq<-mutate(superstore_unq,outlier_lofstatus=ifelse(orderid %in% (vec) ,"Yes","No"))

x<-subset(superstore_unq,superstore_unq$outlier_lofstatus=="Yes")
x

```




## Plot LOF outliers

```{r}


pch <- rep(".", 7000)
pch[lof_outliers] <- "+"
col <- rep("black",7000)
col[lof_outliers] <- "red"
pairs(superstore_lof, pch=pch, col=col)

```



## Random Forest Algorithm 

outForest is a random forest based implementation of the method. Each numeric variable is regressed onto all other variables using a random forest. If the scaled absolute difference between observed value and out-of-bag prediction is suspiciouly large (e.g. more than three times the RMSE of the out-of-bag predictions), then a value is considered an outlier. After identification of outliers, they can be replaced e.g. by predictive mean matching from the non-outliers. outForest package estimates this conditional mean by a random forest.
RF alogorithm  work well without parameter tuning, outliers in the input variables are no issue and the out-of-bag mechanism helps to provide fair outlier scores.

```{r}
#dataframe for outforest
superstore_out<-superstore_unq[,c("sales_amt","profit_amt","quantity","discount","orderday","shipday")]

#fit outforest
outforest_outlier<-outForest(superstore_out, replace = "NA" )
print(outforest_outlier)

```
### Manual Evaluation 

Observed same set of top outliers as LOF algorithm. 

```{r}

#outlier rows, observed values, predicted and RMSE
y<-outliers(outforest_outlier)
row_out<-y$row
superstore_unq<-mutate(superstore_unq,outlier_outstatus=ifelse(row.names(superstore_unq) %in%row_out ,"Yes","No"))

head(outliers(outforest_outlier),21)




```


```{r}

# Outliers per variable
plot(outforest_outlier)

```



```{r}
# Basic plot of the scores of the outliers per variable
plot(outforest_outlier,what="scores")
```
```{r}

Data(outforest_outlier)

```


### K Means Clustering



```{r}

#find k value for clusters


superstore_kmean<-superstore_unq[,c("sales_amt","profit_amt","quantity","discount","orderday","shipday")]


# Elbow method
fviz_nbclust(scale(superstore_kmean), kmeans, method = c("wss"))+
  geom_vline(xintercept = 4, linetype = 2)+
  labs(subtitle = "Elbow method")


```
```{r}
#Silhouette method

fviz_nbclust(scale(superstore_kmean), kmeans, method = "silhouette")+
  labs(subtitle = "Silhouette method")

```


Gap statistic method

```{r}

fviz_nbclust(scale(superstore_kmean), kmeans, nstart = 25,  method = "gap_stat", nboot = 50)+
  labs(subtitle = "Gap statistic method")

```



```{r}

# clusters for k=3

km_clus<-kmeans(scale(superstore_kmean),3,nstart=25)

#Plot clusters
fviz_cluster(km_clus, data = superstore_kmean,palette = "jco",ggtheme = theme_minimal())

```



```{r}
# clusters for k=4

km_clus<-kmeans(scale(superstore_kmean),4,nstart = 25)

#Plot clusters
fviz_cluster(km_clus, data = superstore_kmean,palette = "jco",ggtheme = theme_minimal())

```


## K-Mediods Clustering
```{r}


# for k=3
superstore_kmediod<-superstore_unq[,c("sales_amt","profit_amt","quantity","discount","orderday","shipday")]

kmediod_clus<-pam(scale(superstore_kmediod),3)


fviz_cluster(kmediod_clus, data = superstore_kmediod,palette = "jco",ggtheme = theme_minimal())


```



```{r}


# for k=4


kmediod_clus<-pam(scale(superstore_kmediod),4)


fviz_cluster(kmediod_clus, data = superstore_kmediod,palette = "jco",ggtheme = theme_minimal())


```

## Density Based Clustering Algorithm

DBSCAN is  density-based clustering algorithm, which can be used to identify clusters of any shape in data set containing noise and outliers. DBSCAN stands for Density-Based Spatial Clustering and Application with Noise.DBSCAN does not require the user to specify the number of clusters to be generated and can identify outliers.


```{r}


#dataset for dbscan ,using sales and profit
superstore_dbc<-superstore_unq[,c("sales_amt","profit_amt")]



#log transformation of profit amount ,since negatives in profit translate by adding one and transforming 
superstore_dbc$profit_amt<-log10(superstore_dbc$profit_amt+1 -min(superstore_dbc$profit_amt))


#log transformation of sales amount
superstore_dbc$sales_amt<-log10(superstore_dbc$sales_amt)



```

find  maximum reachability distance (eps)

```{r}
#find value of eps
dbscan::kNNdistplot(superstore_dbc, k = 4)
abline(h = 0.15, lty = 2)
```


```{r}

# cluster assignements with dbscan
dbc<-fpc::dbscan(superstore_dbc,eps=0.1, MinPts  = 5)
fviz_cluster(dbc, superstore_dbc,  geom = "point")

```


The black points are outliers .




```{r}

```



## Responsible ML Framework



## Conclusion




## Bibliography





